Курс по ML, MIPT. Включает в себя итоговые проекты курса:

# Lab1: ML Pipeline

Пайплайн ML, который разбит на 3 части: теоритическое задание, практическое задание на решение задачи мультиклассификации и анализ kernel functions метода опорных векторов.

### Part1: Теоретические вопросы

Освещались темы матричного дифференцирования и вопросы по нормализацию в ML и `kNN`. Была использована библиотека manim для визуализации ответов.

### Part2: Задача классификации

В проекте был предоставлен датасет с 4 классами, среди которых наблюдалась проблемная пара целевых лейблов. Confusion matrixes показывали, что модели часто совершали на них ошибки I и II рода.
Согласно [работе с этим датасетом, но без проблемной пары классов](https://github.com/masl3noki/Y-Y_4.0_ML/blob/main/HW04/Feature%20importances/assignment_importances.ipynb) ошибки характерны именно для классов `opel` и `saab`.

Препроцессинг данных включает в себя только нормализацию без балансировки данных или других техник трансформации датасета. Это также могло негативно повлиять на результат.

### Part3: Исследование SVM

Проект с искусственным датасетом на задачу классификации, целью которого был анализ kernel-функций метода опорных векторов и сравнения этого метода с `RandomForest`.
Наиболее эффективным стал `SVM` с `rbf`-ядром, но и вычислительная сложность (complexity) модели выше, чем у леса.

# Lab2: Комплексная задача

Второй проект с 3 вариантами. В репозитории представлены все 3 варианта на разные датасеты.
Здесь прослеживается интересная тенденция, которая косвенно показывает сложность и эффективность моделей, относительно более простых: от `kNN` до градиентного бустинга.

### Var1: `kNN` vs `DecisionTree`

Анализ эффективности двух классификаторов на сбалансированном датасете путем under-сэмплинга методом `NeighbourhoodCleaningRule`. Этот метод был выбран, опираясь на исследование методов балансировок в Var2 (одинаковые датасеты).

PCA-трансформация датасета и снижение размерности с 63 признаков (после one-hot-кодировки) до 13 признаков позволила увеличить точность `kNN`, однако это привело к снижению точности `DecisionTree`.
Но анализ влияния размерности на эффективность `kNN` и PCA-трансформация всей выборки не позволила классификатору k ближайших соседей приблизиться к эффективности Решающего дерева по всем 4 метрикам.

Решающее дерево без прунинга на оптимальной (не `None`) глубине, согласно кросс-валидации, эффективнее `kNN`, для которого потребовалось делать PCA.

### Var2: `DecisionTree` vs `RandomForest`

Анализ эффективности двух классификаторов на сбалансированном датасете путем under-сэмплинга методом `NeighbourhoodCleaningRule`. Датасет как в Var1. Здесь было подробное исследование популярных методов сэмплирования, таких как `NearMiss`, `ADASYN`, `OneSidedSelection` и др.
В том числе рассматривалась техника добавления весов к объектам выборки. В качестве оценки методов был использован `DecisionTree`, как одна из самых чувствительных к дисбалансу классов моделей.

PCA-трансформация значительно ухудшила предсказания классификаторов, однако `RandomForest` все равно предсказывал лучше одиного `DecisionTree` с прунингом. Как альтернатива случайному лесу была анализирована эффективность `CatBoost` Яндекса.
Катбуст оказался эффективнее леса, т.к. он совершал меньше ошибок II рода.

### Var3: `DecisionTree` vs `AdaBoost`

В отличии от Var1 и Var2 здесь был датасет на задачу регрессии. Целевая метрика - Коэффициент Детерминации $R^2$. Т.к. все признаки числовые, это позволило построить матрицу корреляций и доказать, что PCA не требуется в задаче.
Но по заданию он был необходим, поэтому в конце проекта были сравнительные характеристики между PCA-трансформированным датасетом и выборкой без самого коррелирующего признака.

Однако эти шаги трансформации данных не дали выигрыша в эффективности моделей. Согласно `r2`-метрике самый эффективный алгоритм оценивался в $\approx +0.4$. 
Эту оценку можно увеличить путем выбора оптимального метода балансировки, но этот проект не содержит этих шагов обработки данных.








